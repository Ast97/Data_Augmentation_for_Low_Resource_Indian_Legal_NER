{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIudPM4_PuFO",
        "outputId": "94307600-a8ae-4519-e29c-75848a483703"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/data-augmentation-ner-legal-main/\")"
      ],
      "metadata": {
        "id": "Y6itUuWHPvLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert to BIO Form\n",
        "!python ner_scripts/preprocess_wikiann.py --in_file ./data/raw_test/NER_DEV_JUDGEMENT.json --out_file ./data/bio_format/NER_DEV_JUDGEMENT.txt\n",
        "!python ner_scripts/preprocess_wikiann.py --in_file ./data/raw_test/NER_DEV_PREAMBLE.json --out_file ./data/bio_format/NER_DEV_PREAMBLE.txt\n",
        "!python ner_scripts/preprocess_wikiann.py --in_file ./data/raw_train/NER_TRAIN_JUDGEMENT.json --out_file ./data/bio_format/NER_TRAIN_JUDGEMENT.txt\n",
        "!python ner_scripts/preprocess_wikiann.py --in_file ./data/raw_train/NER_TRAIN_PREAMBLE.json --out_file ./data/bio_format/NER_TRAIN_PREAMBLE.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCjwfUxzP8do",
        "outputId": "14274e6c-ff1d-486a-cc48-b53479e329d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save to ./data/bio_format/NER_DEV_JUDGEMENT.txt\n",
            "Save to ./data/bio_format/NER_DEV_PREAMBLE.txt\n",
            "Save to ./data/bio_format/NER_TRAIN_JUDGEMENT.txt\n",
            "Save to ./data/bio_format/NER_TRAIN_PREAMBLE.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Merge Files to create Train and Test\n",
        "with open('./data/bio_format/NER_DEV_JUDGEMENT.txt', 'r', encoding=\"utf-8\") as f:\n",
        "    NER_DEV_JUDGEMENT = f.readlines()\n",
        "    f.close()\n",
        "with open('./data/bio_format/NER_DEV_PREAMBLE.txt', 'r', encoding=\"utf-8\") as f:\n",
        "    NER_DEV_PREAMBLE = f.readlines()\n",
        "    f.close()\n",
        "with open('./data/bio_format/NER_TRAIN_JUDGEMENT.txt', 'r', encoding=\"utf-8\") as f:\n",
        "    NER_TRAIN_JUDGEMENT = f.readlines()\n",
        "    f.close()\n",
        "with open('./data/bio_format/NER_TRAIN_PREAMBLE.txt', 'r', encoding=\"utf-8\") as f:\n",
        "    NER_TRAIN_PREAMBLE = f.readlines()\n",
        "    f.close()\n",
        "\n",
        "test = NER_DEV_JUDGEMENT + NER_DEV_PREAMBLE\n",
        "train = NER_TRAIN_JUDGEMENT + NER_TRAIN_PREAMBLE\n",
        "split_index = int(len(train) * 0.30)\n",
        "dev = train[:split_index]\n",
        "train = train[split_index:]\n",
        "\n",
        "print('Length of Train, Test and Dev - ', len(train), len(test), len(dev))\n",
        "\n",
        "import os\n",
        "#os.mkdir('./src/datasets/___1.2/')\n",
        "\n",
        "with open('./src/datasets/___1.2/test.txt', 'w', encoding=\"utf-8\") as f:\n",
        "    for line in test:\n",
        "        f.write(line)\n",
        "    f.close()\n",
        "with open('./src/datasets/___1.2/train.txt', 'w', encoding=\"utf-8\") as f:\n",
        "    for line in train:\n",
        "        f.write(line)\n",
        "    f.close()\n",
        "with open('./src/datasets/___1.2/dev.txt', 'w', encoding=\"utf-8\") as f:\n",
        "    for line in dev:\n",
        "        f.write(line)\n",
        "    f.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q80t8a7bP-iH",
        "outputId": "30c8cd9c-d949-4d0f-efcc-808439aa5f65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of Train, Test and Dev -  10 10 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w-mf8v4cQAIf",
        "outputId": "555cf483-bd7b-480c-c4eb-f3870f7ebadf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flair==0.10 (from -r requirements.txt (line 1))\n",
            "  Downloading flair-0.10-py3-none-any.whl (322 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.7/322.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting BackTranslation==0.3.1 (from -r requirements.txt (line 2))\n",
            "  Downloading BackTranslation-0.3.1-py3-none-any.whl (8.9 kB)\n",
            "Collecting beautifulsoup4==4.11.1 (from -r requirements.txt (line 3))\n",
            "  Downloading beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deepl==1.6.0 (from -r requirements.txt (line 4))\n",
            "  Downloading deepl-1.6.0-py3-none-any.whl (31 kB)\n",
            "Collecting fasttext==0.9.2 (from -r requirements.txt (line 5))\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gensim==4.2.0 (from -r requirements.txt (line 6))\n",
            "  Downloading gensim-4.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mysql-connector-python==8.0.29 (from -r requirements.txt (line 7))\n",
            "  Downloading mysql_connector_python-8.0.29-cp310-cp310-manylinux1_x86_64.whl (25.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.2/25.2 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses==0.0.53 (from -r requirements.txt (line 8))\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting SoMaJo==2.2.1 (from -r requirements.txt (line 9))\n",
            "  Downloading SoMaJo-2.2.1-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.5/90.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.64.0 (from -r requirements.txt (line 10))\n",
            "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.19.1 (from -r requirements.txt (line 11))\n",
            "  Downloading transformers-4.19.1-py3-none-any.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-cloud-translate==2.0.1 (from -r requirements.txt (line 12))\n",
            "  Downloading google_cloud_translate-2.0.1-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.9/90.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.10/dist-packages (from flair==0.10->-r requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from flair==0.10->-r requirements.txt (line 1)) (2.0.0+cu118)\n",
            "Collecting segtok>=1.5.7 (from flair==0.10->-r requirements.txt (line 1))\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from flair==0.10->-r requirements.txt (line 1)) (3.7.1)\n",
            "Collecting mpld3==0.3 (from flair==0.10->-r requirements.txt (line 1))\n",
            "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.5/788.5 kB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from flair==0.10->-r requirements.txt (line 1)) (1.2.2)\n",
            "Collecting sqlitedict>=1.6.0 (from flair==0.10->-r requirements.txt (line 1))\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting deprecated>=1.2.4 (from flair==0.10->-r requirements.txt (line 1))\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting bpemb>=0.3.2 (from flair==0.10->-r requirements.txt (line 1))\n",
            "  Downloading bpemb-0.3.4-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from flair==0.10->-r requirements.txt (line 1)) (2022.10.31)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from flair==0.10->-r requirements.txt (line 1)) (0.8.10)\n",
            "Collecting langdetect (from flair==0.10->-r requirements.txt (line 1))\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from flair==0.10->-r requirements.txt (line 1)) (4.9.2)\n",
            "Collecting ftfy (from flair==0.10->-r requirements.txt (line 1))\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece==0.1.95 (from flair==0.10->-r requirements.txt (line 1))\n",
            "  Downloading sentencepiece-0.1.95.tar.gz (508 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.7/508.7 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting konoha<5.0.0,>=4.0.0 (from flair==0.10->-r requirements.txt (line 1))\n",
            "  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n",
            "Collecting janome (from flair==0.10->-r requirements.txt (line 1))\n",
            "  Downloading Janome-0.4.2-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gdown==3.12.2 (from flair==0.10->-r requirements.txt (line 1))\n",
            "  Downloading gdown-3.12.2.tar.gz (8.2 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting huggingface-hub (from flair==0.10->-r requirements.txt (line 1))\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting conllu>=4.0 (from flair==0.10->-r requirements.txt (line 1))\n",
            "  Downloading conllu-4.5.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting more-itertools~=8.8.0 (from flair==0.10->-r requirements.txt (line 1))\n",
            "  Downloading more_itertools-8.8.0-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wikipedia-api (from flair==0.10->-r requirements.txt (line 1))\n",
            "  Downloading Wikipedia_API-0.5.8-py3-none-any.whl (13 kB)\n",
            "Collecting googletrans==4.0.0rc1 (from BackTranslation==0.3.1->-r requirements.txt (line 2))\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from BackTranslation==0.3.1->-r requirements.txt (line 2)) (3.8.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4==4.11.1->-r requirements.txt (line 3)) (2.4.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from deepl==1.6.0->-r requirements.txt (line 4)) (2.27.1)\n",
            "Collecting pybind11>=2.2 (from fasttext==0.9.2->-r requirements.txt (line 5))\n",
            "  Using cached pybind11-2.10.4-py3-none-any.whl (222 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext==0.9.2->-r requirements.txt (line 5)) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext==0.9.2->-r requirements.txt (line 5)) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from gensim==4.2.0->-r requirements.txt (line 6)) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim==4.2.0->-r requirements.txt (line 6)) (6.3.0)\n",
            "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from mysql-connector-python==8.0.29->-r requirements.txt (line 7)) (3.20.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.0.53->-r requirements.txt (line 8)) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.0.53->-r requirements.txt (line 8)) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.0.53->-r requirements.txt (line 8)) (1.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.1->-r requirements.txt (line 11)) (3.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.1->-r requirements.txt (line 11)) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.1->-r requirements.txt (line 11)) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers==4.19.1->-r requirements.txt (line 11))\n",
            "  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-api-core[grpc]<2.0.0dev,>=1.15.0 (from google-cloud-translate==2.0.1->-r requirements.txt (line 12))\n",
            "  Downloading google_api_core-1.34.0-py3-none-any.whl (120 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.2/120.2 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-cloud-core<2.0dev,>=1.1.0 (from google-cloud-translate==2.0.1->-r requirements.txt (line 12))\n",
            "  Downloading google_cloud_core-1.7.3-py2.py3-none-any.whl (28 kB)\n",
            "Collecting httpx==0.13.3 (from googletrans==4.0.0rc1->BackTranslation==0.3.1->-r requirements.txt (line 2))\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1->BackTranslation==0.3.1->-r requirements.txt (line 2)) (2022.12.7)\n",
            "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0rc1->BackTranslation==0.3.1->-r requirements.txt (line 2))\n",
            "  Downloading hstspreload-2023.1.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1->BackTranslation==0.3.1->-r requirements.txt (line 2)) (1.3.0)\n",
            "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0rc1->BackTranslation==0.3.1->-r requirements.txt (line 2))\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0rc1->BackTranslation==0.3.1->-r requirements.txt (line 2))\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0rc1->BackTranslation==0.3.1->-r requirements.txt (line 2))\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0rc1->BackTranslation==0.3.1->-r requirements.txt (line 2))\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1->BackTranslation==0.3.1->-r requirements.txt (line 2))\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1->BackTranslation==0.3.1->-r requirements.txt (line 2))\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1->BackTranslation==0.3.1->-r requirements.txt (line 2))\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1->BackTranslation==0.3.1->-r requirements.txt (line 2))\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.4->flair==0.10->-r requirements.txt (line 1)) (1.14.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1->-r requirements.txt (line 12)) (1.59.0)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1->-r requirements.txt (line 12)) (2.17.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1->-r requirements.txt (line 12)) (1.54.0)\n",
            "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1->-r requirements.txt (line 12)) (1.48.2)\n",
            "Collecting google-auth<3.0dev,>=1.25.0 (from google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1->-r requirements.txt (line 12))\n",
            "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.9/152.9 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->flair==0.10->-r requirements.txt (line 1)) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->flair==0.10->-r requirements.txt (line 1)) (4.5.0)\n",
            "Collecting importlib-metadata<4.0.0,>=3.7.0 (from konoha<5.0.0,>=4.0.0->flair==0.10->-r requirements.txt (line 1))\n",
            "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
            "Collecting overrides<4.0.0,>=3.0.0 (from konoha<5.0.0,>=4.0.0->flair==0.10->-r requirements.txt (line 1))\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair==0.10->-r requirements.txt (line 1)) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair==0.10->-r requirements.txt (line 1)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair==0.10->-r requirements.txt (line 1)) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair==0.10->-r requirements.txt (line 1)) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair==0.10->-r requirements.txt (line 1)) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair==0.10->-r requirements.txt (line 1)) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->deepl==1.6.0->-r requirements.txt (line 4)) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->deepl==1.6.0->-r requirements.txt (line 4)) (2.0.12)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->flair==0.10->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair==0.10->-r requirements.txt (line 1)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair==0.10->-r requirements.txt (line 1)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair==0.10->-r requirements.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair==0.10->-r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.8,>=1.5.0->flair==0.10->-r requirements.txt (line 1)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.8,>=1.5.0->flair==0.10->-r requirements.txt (line 1)) (16.0.3)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->flair==0.10->-r requirements.txt (line 1)) (0.2.6)\n",
            "Collecting cachetools<5.0,>=2.0.0 (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1->-r requirements.txt (line 12))\n",
            "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1->-r requirements.txt (line 12)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1->-r requirements.txt (line 12)) (4.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair==0.10->-r requirements.txt (line 1)) (3.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.8,>=1.5.0->flair==0.10->-r requirements.txt (line 1)) (2.1.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->deepl==1.6.0->-r requirements.txt (line 4)) (1.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.8,>=1.5.0->flair==0.10->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.15.0->google-cloud-translate==2.0.1->-r requirements.txt (line 12)) (0.5.0)\n",
            "Building wheels for collected packages: fasttext, sacremoses, gdown, googletrans, mpld3, sentencepiece, sqlitedict, langdetect, overrides\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4393347 sha256=dae84e9bfa247e1560129376ab86bab57fb73fac8a6bc79b986297807dbaae53\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=6a09a626ed7b043c1361d4150fc98a2e33122441857f3be9ff600538f37734b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "  Building wheel for gdown (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-3.12.2-py3-none-any.whl size=9675 sha256=90c68893af5e879994998c3652eaf4b4dadc061c7a7320a39d706fe6d6d7556a\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/45/ac/c7557ccd8fe79de5da94d7b39b5ca92f22f86a0f85367e2b0a\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17397 sha256=eefc0279e0a6a5bf4b710b29fba5b642210ea68e4875d708696d18860ca00fcf\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/59/9f/7372f0cf70160fe61b528532e1a7c8498c4becd6bcffb022de\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116685 sha256=6d816be64008d4d7a3df6b5974ccb2d292e30b0621b6de7f9449c67754cd74bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/92/f7/45d9aac5dcfb1c2a1761a272365599cc7ba1050ce211a3fd9a\n",
            "  Building wheel for sentencepiece (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentencepiece: filename=sentencepiece-0.1.95-cp310-cp310-linux_x86_64.whl size=1546197 sha256=71a4701d6878a214d20f2733481e8615da38c42a902bc0d95605cac7f2ab3edd\n",
            "  Stored in directory: /root/.cache/pip/wheels/ef/a4/01/5a500fc0c5a38917ef408c245eb40b7ac96f4a30fc6a346a4c\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16863 sha256=dc88e65d1016ccc6ba655dd5ef2816d275233c6f9bfe62ecb8558c285009f360\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=52187e55043f8befecfa06ab069228bbc625f5e4ad41130e34b8b6fb2e951e61\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10173 sha256=7e34e229ae476eb3666b878c195c3358649cec42ecbcacda0c7d6362bbd4c36c\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/23/63/4d5849844f8f9d32be09e1b9b278e80de2d8314fbf1e28068b\n",
            "Successfully built fasttext sacremoses gdown googletrans mpld3 sentencepiece sqlitedict langdetect overrides\n",
            "Installing collected packages: tokenizers, sqlitedict, sentencepiece, rfc3986, overrides, mpld3, janome, hyperframe, hpack, h11, chardet, tqdm, SoMaJo, segtok, pybind11, mysql-connector-python, more-itertools, langdetect, importlib-metadata, idna, hstspreload, h2, ftfy, deprecated, conllu, cachetools, beautifulsoup4, sacremoses, httpcore, google-auth, gensim, fasttext, wikipedia-api, konoha, huggingface-hub, httpx, google-api-core, deepl, bpemb, transformers, googletrans, google-cloud-core, gdown, google-cloud-translate, BackTranslation, flair\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 4.0.0\n",
            "    Uninstalling chardet-4.0.0:\n",
            "      Successfully uninstalled chardet-4.0.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.65.0\n",
            "    Uninstalling tqdm-4.65.0:\n",
            "      Successfully uninstalled tqdm-4.65.0\n",
            "  Attempting uninstall: more-itertools\n",
            "    Found existing installation: more-itertools 9.1.0\n",
            "    Uninstalling more-itertools-9.1.0:\n",
            "      Successfully uninstalled more-itertools-9.1.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.3.0\n",
            "    Uninstalling cachetools-5.3.0:\n",
            "      Successfully uninstalled cachetools-5.3.0\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.11.2\n",
            "    Uninstalling beautifulsoup4-4.11.2:\n",
            "      Successfully uninstalled beautifulsoup4-4.11.2\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.17.3\n",
            "    Uninstalling google-auth-2.17.3:\n",
            "      Successfully uninstalled google-auth-2.17.3\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 4.3.1\n",
            "    Uninstalling gensim-4.3.1:\n",
            "      Successfully uninstalled gensim-4.3.1\n",
            "  Attempting uninstall: google-api-core\n",
            "    Found existing installation: google-api-core 2.11.0\n",
            "    Uninstalling google-api-core-2.11.0:\n",
            "      Successfully uninstalled google-api-core-2.11.0\n",
            "  Attempting uninstall: google-cloud-core\n",
            "    Found existing installation: google-cloud-core 2.3.2\n",
            "    Uninstalling google-cloud-core-2.3.2:\n",
            "      Successfully uninstalled google-cloud-core-2.3.2\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.6.6\n",
            "    Uninstalling gdown-4.6.6:\n",
            "      Successfully uninstalled gdown-4.6.6\n",
            "  Attempting uninstall: google-cloud-translate\n",
            "    Found existing installation: google-cloud-translate 3.11.1\n",
            "    Uninstalling google-cloud-translate-3.11.1:\n",
            "      Successfully uninstalled google-cloud-translate-3.11.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-auth-oauthlib 1.0.0 requires google-auth>=2.15.0, but you have google-auth 1.35.0 which is incompatible.\n",
            "google-cloud-storage 2.8.0 requires google-cloud-core<3.0dev,>=2.3.0, but you have google-cloud-core 1.7.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed BackTranslation-0.3.1 SoMaJo-2.2.1 beautifulsoup4-4.11.1 bpemb-0.3.4 cachetools-4.2.4 chardet-3.0.4 conllu-4.5.2 deepl-1.6.0 deprecated-1.2.13 fasttext-0.9.2 flair-0.10 ftfy-6.1.1 gdown-3.12.2 gensim-4.2.0 google-api-core-1.34.0 google-auth-1.35.0 google-cloud-core-1.7.3 google-cloud-translate-2.0.1 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2023.1.1 httpcore-0.9.1 httpx-0.13.3 huggingface-hub-0.14.1 hyperframe-5.2.0 idna-2.10 importlib-metadata-3.10.1 janome-0.4.2 konoha-4.6.5 langdetect-1.0.9 more-itertools-8.8.0 mpld3-0.3 mysql-connector-python-8.0.29 overrides-3.1.0 pybind11-2.10.4 rfc3986-1.5.0 sacremoses-0.0.53 segtok-1.5.11 sentencepiece-0.1.95 sqlitedict-2.1.0 tokenizers-0.12.1 tqdm-4.64.0 transformers-4.19.1 wikipedia-api-0.5.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Confirm that the GPU is detected\n",
        "\n",
        "assert torch.cuda.is_available()\n",
        "\n",
        "# Get the GPU device name.\n",
        "\n",
        "device_name = torch.cuda.get_device_name()\n",
        "n_gpu = torch.cuda.device_count()\n",
        "print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "#device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXXNerQ-QBeX",
        "outputId": "67f9ca5f-7c01-47d1-9b31-e24da2ac87e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found device: Tesla T4, n_gpu: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('./src')"
      ],
      "metadata": {
        "id": "HHGbsNNpQHIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python aug/synonym_replace.py datasets/___1.1 0.6 fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vprv3fHyQIhj",
        "outputId": "8b6b0ede-2733-4e4a-dbba-4f85e0614ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-14 03:28:07.438268: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-14 03:28:08.692445: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-05-14 03:28:13,980 Reading data from datasets/___1.1\n",
            "2023-05-14 03:28:13,980 Train: datasets/___1.1/train.txt\n",
            "2023-05-14 03:28:13,981 Dev: datasets/___1.1/dev.txt\n",
            "2023-05-14 03:28:13,981 Test: datasets/___1.1/test.txt\n",
            "initializing source...\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "starting augmentation...\n",
            "100% 5851/5851 [30:35<00:00,  3.19it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python aug/synonym_replace.py datasets/___1.1 0.6 thesaurus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQ9OM7yCQKf4",
        "outputId": "37ef5d7f-e599-4c35-c896-98d86ac2d00c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-14 03:59:39.035483: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-14 03:59:40.472755: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-05-14 03:59:45,598 Reading data from datasets/___1.1\n",
            "2023-05-14 03:59:45,598 Train: datasets/___1.1/train.txt\n",
            "2023-05-14 03:59:45,598 Dev: datasets/___1.1/dev.txt\n",
            "2023-05-14 03:59:45,598 Test: datasets/___1.1/test.txt\n",
            "initializing source...\n",
            "initialization of thesaurus is included in SynonymReplacement function\n",
            "starting augmentation...\n",
            "100% 5851/5851 [54:37<00:00,  1.78it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python model_bilstm.py datasets/cSR1.0f0.6pthe  datasets/cSR1.0f0.6pthe  0.05 32 gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_dubTdjXPay",
        "outputId": "2542eb89-b7c7-44a4-cf88-181f53b832e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-14 04:57:20.397512: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-14 04:57:21.744001: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-05-14 04:57:26,599 Reading data from datasets/cSR1.0f0.6pthe\n",
            "2023-05-14 04:57:26,600 Train: datasets/cSR1.0f0.6pthe/train.txt\n",
            "2023-05-14 04:57:26,600 Dev: datasets/cSR1.0f0.6pthe/dev.txt\n",
            "2023-05-14 04:57:26,600 Test: datasets/cSR1.0f0.6pthe/test.txt\n",
            "2023-05-14 04:57:33,107 Computing label dictionary. Progress:\n",
            "100% 6009/6009 [00:00<00:00, 11702.40it/s]\n",
            "2023-05-14 04:57:33,685 Corpus contains the labels: ner (#330284)\n",
            "2023-05-14 04:57:33,685 Created (for label 'ner') Dictionary with 30 tags: <unk>, O, B-STATUTE, I-STATUTE, B-JUDGE, B-PRECEDENT, I-PRECEDENT, B-PROVISION, I-PROVISION, B-OTHER_PERSON, B-GPE, B-ORG, I-ORG, B-PETITIONER, B-DATE, B-WITNESS, I-WITNESS, B-COURT, I-COURT, B-CASE_NUMBER, I-CASE_NUMBER, I-OTHER_PERSON, B-RESPONDENT, I-RESPONDENT, I-DATE, I-PETITIONER, I-JUDGE, I-GPE, B-LAWYER, I-LAWYER\n",
            "2023-05-14 04:57:34,621 https://flair.informatik.hu-berlin.de/resources/embeddings/token/en-fasttext-news-300d-1M.vectors.npy not found in cache, downloading to /tmp/tmpewxirjt6\n",
            "100% 1200000128/1200000128 [01:06<00:00, 18053114.95B/s]\n",
            "2023-05-14 04:58:41,584 copying /tmp/tmpewxirjt6 to cache at /root/.flair/embeddings/en-fasttext-news-300d-1M.vectors.npy\n",
            "2023-05-14 04:58:45,903 removing temp file /tmp/tmpewxirjt6\n",
            "2023-05-14 04:58:46,836 https://flair.informatik.hu-berlin.de/resources/embeddings/token/en-fasttext-news-300d-1M not found in cache, downloading to /tmp/tmpe4vuwm8u\n",
            "100% 54600983/54600983 [00:03<00:00, 13895441.60B/s]\n",
            "2023-05-14 04:58:51,260 copying /tmp/tmpe4vuwm8u to cache at /root/.flair/embeddings/en-fasttext-news-300d-1M\n",
            "2023-05-14 04:58:51,322 removing temp file /tmp/tmpe4vuwm8u\n",
            "2023-05-14 04:59:02,880 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/news-forward-0.4.1.pt not found in cache, downloading to /tmp/tmpra8n4wok\n",
            "100% 73034624/73034624 [00:05<00:00, 14575757.74B/s]\n",
            "2023-05-14 04:59:08,390 copying /tmp/tmpra8n4wok to cache at /root/.flair/embeddings/news-forward-0.4.1.pt\n",
            "2023-05-14 04:59:08,474 removing temp file /tmp/tmpra8n4wok\n",
            "2023-05-14 04:59:10,011 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/news-backward-0.4.1.pt not found in cache, downloading to /tmp/tmp29qqofzl\n",
            "100% 73034575/73034575 [00:05<00:00, 14550895.68B/s]\n",
            "2023-05-14 04:59:15,522 copying /tmp/tmp29qqofzl to cache at /root/.flair/embeddings/news-backward-0.4.1.pt\n",
            "2023-05-14 04:59:15,607 removing temp file /tmp/tmp29qqofzl\n",
            "2023-05-14 04:59:16,791 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 04:59:16,792 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings(\n",
            "      'en'\n",
            "      (embedding): Embedding(1000001, 300)\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_2): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.25, inplace=False)\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=4396, out_features=4396, bias=True)\n",
            "  (rnn): LSTM(4396, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=32, bias=True)\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2023-05-14 04:59:16,792 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 04:59:16,792 Corpus: \"Corpus: 6009 train + 4109 dev + 982 test sentences\"\n",
            "2023-05-14 04:59:16,792 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 04:59:16,792 Parameters:\n",
            "2023-05-14 04:59:16,793  - learning_rate: \"0.05\"\n",
            "2023-05-14 04:59:16,793  - mini_batch_size: \"32\"\n",
            "2023-05-14 04:59:16,793  - patience: \"5\"\n",
            "2023-05-14 04:59:16,793  - anneal_factor: \"0.5\"\n",
            "2023-05-14 04:59:16,793  - max_epochs: \"10\"\n",
            "2023-05-14 04:59:16,793  - shuffle: \"True\"\n",
            "2023-05-14 04:59:16,793  - train_with_dev: \"False\"\n",
            "2023-05-14 04:59:16,793  - batch_growth_annealing: \"False\"\n",
            "2023-05-14 04:59:16,794 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 04:59:16,794 Model training base path: \"resources/taggers/sota-ner-flair\"\n",
            "2023-05-14 04:59:16,794 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 04:59:16,794 Device: cuda:0\n",
            "2023-05-14 04:59:16,794 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 04:59:16,794 Embeddings storage mode: gpu\n",
            "2023-05-14 04:59:16,802 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 04:59:27,959 epoch 1 - iter 18/188 - loss 1.75743572 - samples/sec: 51.64 - lr: 0.050000\n",
            "2023-05-14 04:59:38,571 epoch 1 - iter 36/188 - loss 1.29185449 - samples/sec: 54.29 - lr: 0.050000\n",
            "2023-05-14 04:59:48,869 epoch 1 - iter 54/188 - loss 1.12326552 - samples/sec: 55.95 - lr: 0.050000\n",
            "2023-05-14 04:59:59,580 epoch 1 - iter 72/188 - loss 1.00706167 - samples/sec: 53.79 - lr: 0.050000\n",
            "2023-05-14 05:00:12,293 epoch 1 - iter 90/188 - loss 0.91468929 - samples/sec: 45.32 - lr: 0.050000\n",
            "2023-05-14 05:00:23,712 epoch 1 - iter 108/188 - loss 0.84842385 - samples/sec: 50.46 - lr: 0.050000\n",
            "2023-05-14 05:00:35,148 epoch 1 - iter 126/188 - loss 0.80298013 - samples/sec: 50.38 - lr: 0.050000\n",
            "2023-05-14 05:01:27,378 epoch 1 - iter 144/188 - loss 0.88457486 - samples/sec: 11.03 - lr: 0.050000\n",
            "2023-05-14 05:02:59,163 epoch 1 - iter 162/188 - loss 0.88402926 - samples/sec: 6.28 - lr: 0.050000\n",
            "2023-05-14 05:04:46,284 epoch 1 - iter 180/188 - loss 0.86778139 - samples/sec: 5.38 - lr: 0.050000\n",
            "2023-05-14 05:05:03,487 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 05:05:03,488 EPOCH 1 done: loss 0.8662 - lr 0.0500000\n",
            "2023-05-14 05:06:25,754 DEV : loss 0.4944792687892914 - f1-score (micro avg)  0.1164\n",
            "2023-05-14 05:06:25,782 BAD EPOCHS (no improvement): 0\n",
            "2023-05-14 05:06:26,067 saving best model\n",
            "2023-05-14 05:06:50,517 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 05:07:06,317 epoch 2 - iter 18/188 - loss 0.67297836 - samples/sec: 36.47 - lr: 0.050000\n",
            "2023-05-14 05:07:19,238 epoch 2 - iter 36/188 - loss 0.65011970 - samples/sec: 44.60 - lr: 0.050000\n",
            "2023-05-14 05:07:28,493 epoch 2 - iter 54/188 - loss 0.63452190 - samples/sec: 62.25 - lr: 0.050000\n",
            "2023-05-14 05:07:38,915 epoch 2 - iter 72/188 - loss 0.61909328 - samples/sec: 55.28 - lr: 0.050000\n",
            "2023-05-14 05:07:51,405 epoch 2 - iter 90/188 - loss 0.59953513 - samples/sec: 46.13 - lr: 0.050000\n",
            "2023-05-14 05:08:00,726 epoch 2 - iter 108/188 - loss 0.58267346 - samples/sec: 61.82 - lr: 0.050000\n",
            "2023-05-14 05:08:10,557 epoch 2 - iter 126/188 - loss 0.56883822 - samples/sec: 58.60 - lr: 0.050000\n",
            "2023-05-14 05:08:21,211 epoch 2 - iter 144/188 - loss 0.55250107 - samples/sec: 54.08 - lr: 0.050000\n",
            "2023-05-14 05:08:30,895 epoch 2 - iter 162/188 - loss 0.53955162 - samples/sec: 59.50 - lr: 0.050000\n",
            "2023-05-14 05:08:47,147 epoch 2 - iter 180/188 - loss 0.52209412 - samples/sec: 35.45 - lr: 0.050000\n",
            "2023-05-14 05:08:51,914 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 05:08:51,917 EPOCH 2 done: loss 0.5181 - lr 0.0500000\n",
            "2023-05-14 05:09:09,374 DEV : loss 0.321498304605484 - f1-score (micro avg)  0.3939\n",
            "2023-05-14 05:09:09,403 BAD EPOCHS (no improvement): 0\n",
            "2023-05-14 05:09:09,677 saving best model\n",
            "2023-05-14 05:09:33,004 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 05:09:46,690 epoch 3 - iter 18/188 - loss 0.39918173 - samples/sec: 42.10 - lr: 0.050000\n",
            "2023-05-14 05:10:00,090 epoch 3 - iter 36/188 - loss 0.39032622 - samples/sec: 43.01 - lr: 0.050000\n",
            "2023-05-14 05:10:12,000 epoch 3 - iter 54/188 - loss 0.39196527 - samples/sec: 48.38 - lr: 0.050000\n",
            "2023-05-14 05:10:22,854 epoch 3 - iter 72/188 - loss 0.38111701 - samples/sec: 53.09 - lr: 0.050000\n",
            "2023-05-14 05:10:31,249 epoch 3 - iter 90/188 - loss 0.37994544 - samples/sec: 68.64 - lr: 0.050000\n",
            "2023-05-14 05:10:42,683 epoch 3 - iter 108/188 - loss 0.37902311 - samples/sec: 50.39 - lr: 0.050000\n",
            "2023-05-14 05:10:54,643 epoch 3 - iter 126/188 - loss 0.37130015 - samples/sec: 48.18 - lr: 0.050000\n",
            "2023-05-14 05:11:10,944 epoch 3 - iter 144/188 - loss 0.36418873 - samples/sec: 35.35 - lr: 0.050000\n",
            "2023-05-14 05:11:21,084 epoch 3 - iter 162/188 - loss 0.36156936 - samples/sec: 56.83 - lr: 0.050000\n",
            "2023-05-14 05:11:30,558 epoch 3 - iter 180/188 - loss 0.35713838 - samples/sec: 60.83 - lr: 0.050000\n",
            "2023-05-14 05:11:34,516 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 05:11:34,516 EPOCH 3 done: loss 0.3556 - lr 0.0500000\n",
            "2023-05-14 05:11:49,892 DEV : loss 0.24627536535263062 - f1-score (micro avg)  0.5127\n",
            "2023-05-14 05:11:49,941 BAD EPOCHS (no improvement): 0\n",
            "2023-05-14 05:11:50,264 saving best model\n",
            "2023-05-14 05:12:15,832 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 05:12:28,239 epoch 4 - iter 18/188 - loss 0.29464444 - samples/sec: 46.44 - lr: 0.050000\n",
            "2023-05-14 05:12:44,668 epoch 4 - iter 36/188 - loss 0.29869032 - samples/sec: 35.07 - lr: 0.050000\n",
            "2023-05-14 05:12:53,702 epoch 4 - iter 54/188 - loss 0.29459552 - samples/sec: 63.78 - lr: 0.050000\n",
            "2023-05-14 05:13:04,936 epoch 4 - iter 72/188 - loss 0.29278219 - samples/sec: 51.29 - lr: 0.050000\n",
            "2023-05-14 05:13:14,976 epoch 4 - iter 90/188 - loss 0.29143894 - samples/sec: 57.40 - lr: 0.050000\n",
            "2023-05-14 05:13:26,320 epoch 4 - iter 108/188 - loss 0.28790295 - samples/sec: 50.79 - lr: 0.050000\n",
            "2023-05-14 05:13:36,089 epoch 4 - iter 126/188 - loss 0.28403616 - samples/sec: 58.99 - lr: 0.050000\n",
            "2023-05-14 05:13:46,463 epoch 4 - iter 144/188 - loss 0.28426108 - samples/sec: 55.56 - lr: 0.050000\n",
            "2023-05-14 05:13:56,812 epoch 4 - iter 162/188 - loss 0.28326877 - samples/sec: 55.68 - lr: 0.050000\n",
            "2023-05-14 05:14:11,801 epoch 4 - iter 180/188 - loss 0.28048324 - samples/sec: 38.44 - lr: 0.050000\n",
            "2023-05-14 05:14:16,118 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 05:14:16,121 EPOCH 4 done: loss 0.2804 - lr 0.0500000\n",
            "2023-05-14 05:14:33,327 DEV : loss 0.20861268043518066 - f1-score (micro avg)  0.5775\n",
            "2023-05-14 05:14:33,356 BAD EPOCHS (no improvement): 0\n",
            "2023-05-14 05:14:33,360 saving best model\n",
            "2023-05-14 05:14:40,516 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 05:14:50,395 epoch 5 - iter 18/188 - loss 0.25978598 - samples/sec: 58.32 - lr: 0.050000\n",
            "2023-05-14 05:15:07,480 epoch 5 - iter 36/188 - loss 0.25822674 - samples/sec: 33.73 - lr: 0.050000\n",
            "2023-05-14 05:15:17,797 epoch 5 - iter 54/188 - loss 0.25997889 - samples/sec: 55.85 - lr: 0.050000\n",
            "2023-05-14 05:15:27,452 epoch 5 - iter 72/188 - loss 0.25261347 - samples/sec: 59.68 - lr: 0.050000\n",
            "2023-05-14 05:15:37,225 epoch 5 - iter 90/188 - loss 0.24544024 - samples/sec: 58.98 - lr: 0.050000\n",
            "2023-05-14 05:15:48,690 epoch 5 - iter 108/188 - loss 0.24049838 - samples/sec: 50.26 - lr: 0.050000\n",
            "2023-05-14 05:16:05,616 epoch 5 - iter 126/188 - loss 0.23586081 - samples/sec: 34.04 - lr: 0.050000\n",
            "2023-05-14 05:16:15,842 epoch 5 - iter 144/188 - loss 0.23587762 - samples/sec: 56.35 - lr: 0.050000\n",
            "2023-05-14 05:16:27,869 epoch 5 - iter 162/188 - loss 0.23460571 - samples/sec: 47.90 - lr: 0.050000\n",
            "2023-05-14 05:16:38,025 epoch 5 - iter 180/188 - loss 0.23204479 - samples/sec: 56.74 - lr: 0.050000\n",
            "2023-05-14 05:16:43,176 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 05:16:43,179 EPOCH 5 done: loss 0.2317 - lr 0.0500000\n",
            "2023-05-14 05:16:58,153 DEV : loss 0.1766815483570099 - f1-score (micro avg)  0.6181\n",
            "2023-05-14 05:16:58,204 BAD EPOCHS (no improvement): 0\n",
            "2023-05-14 05:16:58,482 saving best model\n",
            "2023-05-14 05:17:06,334 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 05:17:21,270 epoch 6 - iter 18/188 - loss 0.20684704 - samples/sec: 38.58 - lr: 0.050000\n",
            "2023-05-14 05:17:33,668 epoch 6 - iter 36/188 - loss 0.21224683 - samples/sec: 46.49 - lr: 0.050000\n",
            "2023-05-14 05:17:44,297 epoch 6 - iter 54/188 - loss 0.20837342 - samples/sec: 54.22 - lr: 0.050000\n",
            "2023-05-14 05:17:53,469 epoch 6 - iter 72/188 - loss 0.21011965 - samples/sec: 62.83 - lr: 0.050000\n",
            "2023-05-14 05:18:03,345 epoch 6 - iter 90/188 - loss 0.20754203 - samples/sec: 58.35 - lr: 0.050000\n",
            "2023-05-14 05:18:13,541 epoch 6 - iter 108/188 - loss 0.20542303 - samples/sec: 56.53 - lr: 0.050000\n",
            "2023-05-14 05:18:25,210 epoch 6 - iter 126/188 - loss 0.20536969 - samples/sec: 49.37 - lr: 0.050000\n",
            "2023-05-14 05:18:41,756 epoch 6 - iter 144/188 - loss 0.20249112 - samples/sec: 34.82 - lr: 0.050000\n",
            "2023-05-14 05:18:52,000 epoch 6 - iter 162/188 - loss 0.20216443 - samples/sec: 56.26 - lr: 0.050000\n",
            "2023-05-14 05:19:02,507 epoch 6 - iter 180/188 - loss 0.20124379 - samples/sec: 54.84 - lr: 0.050000\n",
            "2023-05-14 05:19:07,132 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 05:19:07,134 EPOCH 6 done: loss 0.2003 - lr 0.0500000\n",
            "2023-05-14 05:19:25,097 DEV : loss 0.16237299144268036 - f1-score (micro avg)  0.6389\n",
            "2023-05-14 05:19:25,125 BAD EPOCHS (no improvement): 0\n",
            "2023-05-14 05:19:25,394 saving best model\n",
            "2023-05-14 05:19:33,350 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 05:19:45,077 epoch 7 - iter 18/188 - loss 0.18859266 - samples/sec: 49.14 - lr: 0.050000\n",
            "2023-05-14 05:19:57,948 epoch 7 - iter 36/188 - loss 0.18778541 - samples/sec: 44.77 - lr: 0.050000\n",
            "2023-05-14 05:20:13,966 epoch 7 - iter 54/188 - loss 0.18442891 - samples/sec: 35.97 - lr: 0.050000\n",
            "2023-05-14 05:20:24,766 epoch 7 - iter 72/188 - loss 0.18530655 - samples/sec: 53.35 - lr: 0.050000\n",
            "2023-05-14 05:20:35,907 epoch 7 - iter 90/188 - loss 0.18440452 - samples/sec: 51.73 - lr: 0.050000\n",
            "2023-05-14 05:20:45,256 epoch 7 - iter 108/188 - loss 0.18178336 - samples/sec: 61.63 - lr: 0.050000\n",
            "2023-05-14 05:20:55,103 epoch 7 - iter 126/188 - loss 0.18109099 - samples/sec: 58.52 - lr: 0.050000\n",
            "2023-05-14 05:21:08,262 epoch 7 - iter 144/188 - loss 0.18173648 - samples/sec: 43.78 - lr: 0.050000\n",
            "2023-05-14 05:21:17,475 epoch 7 - iter 162/188 - loss 0.18119528 - samples/sec: 62.54 - lr: 0.050000\n",
            "2023-05-14 05:21:27,973 epoch 7 - iter 180/188 - loss 0.17921728 - samples/sec: 54.88 - lr: 0.050000\n",
            "2023-05-14 05:21:31,530 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 05:21:31,531 EPOCH 7 done: loss 0.1789 - lr 0.0500000\n",
            "2023-05-14 05:21:50,737 DEV : loss 0.14462964236736298 - f1-score (micro avg)  0.6568\n",
            "2023-05-14 05:21:50,766 BAD EPOCHS (no improvement): 0\n",
            "2023-05-14 05:21:51,071 saving best model\n",
            "2023-05-14 05:21:59,549 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 05:22:14,249 epoch 8 - iter 18/188 - loss 0.16978795 - samples/sec: 39.20 - lr: 0.050000\n",
            "2023-05-14 05:22:27,652 epoch 8 - iter 36/188 - loss 0.16741914 - samples/sec: 43.00 - lr: 0.050000\n",
            "2023-05-14 05:22:38,877 epoch 8 - iter 54/188 - loss 0.16454325 - samples/sec: 51.33 - lr: 0.050000\n",
            "2023-05-14 05:22:47,752 epoch 8 - iter 72/188 - loss 0.16632349 - samples/sec: 64.93 - lr: 0.050000\n",
            "2023-05-14 05:22:59,452 epoch 8 - iter 90/188 - loss 0.17107605 - samples/sec: 49.25 - lr: 0.050000\n",
            "2023-05-14 05:23:14,305 epoch 8 - iter 108/188 - loss 0.16576890 - samples/sec: 38.79 - lr: 0.050000\n",
            "2023-05-14 05:23:24,813 epoch 8 - iter 126/188 - loss 0.16703374 - samples/sec: 54.84 - lr: 0.050000\n",
            "2023-05-14 05:23:34,888 epoch 8 - iter 144/188 - loss 0.16578385 - samples/sec: 57.20 - lr: 0.050000\n",
            "2023-05-14 05:23:44,754 epoch 8 - iter 162/188 - loss 0.16460922 - samples/sec: 58.41 - lr: 0.050000\n",
            "2023-05-14 05:23:54,379 epoch 8 - iter 180/188 - loss 0.16449155 - samples/sec: 59.87 - lr: 0.050000\n",
            "2023-05-14 05:23:59,402 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 05:23:59,404 EPOCH 8 done: loss 0.1636 - lr 0.0500000\n",
            "2023-05-14 05:24:14,697 DEV : loss 0.14330141246318817 - f1-score (micro avg)  0.6596\n",
            "2023-05-14 05:24:14,726 BAD EPOCHS (no improvement): 0\n",
            "2023-05-14 05:24:14,728 saving best model\n",
            "2023-05-14 05:24:22,024 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 05:24:31,750 epoch 9 - iter 18/188 - loss 0.14762163 - samples/sec: 59.26 - lr: 0.050000\n",
            "2023-05-14 05:24:47,048 epoch 9 - iter 36/188 - loss 0.14671049 - samples/sec: 37.66 - lr: 0.050000\n",
            "2023-05-14 05:24:58,473 epoch 9 - iter 54/188 - loss 0.14440510 - samples/sec: 50.43 - lr: 0.050000\n",
            "2023-05-14 05:25:13,367 epoch 9 - iter 72/188 - loss 0.14418714 - samples/sec: 38.68 - lr: 0.050000\n",
            "2023-05-14 05:25:24,243 epoch 9 - iter 90/188 - loss 0.14726891 - samples/sec: 52.98 - lr: 0.050000\n",
            "2023-05-14 05:25:34,268 epoch 9 - iter 108/188 - loss 0.15188908 - samples/sec: 57.47 - lr: 0.050000\n",
            "2023-05-14 05:25:45,154 epoch 9 - iter 126/188 - loss 0.15246665 - samples/sec: 52.93 - lr: 0.050000\n",
            "2023-05-14 05:25:57,675 epoch 9 - iter 144/188 - loss 0.15142200 - samples/sec: 46.01 - lr: 0.050000\n",
            "2023-05-14 05:26:07,558 epoch 9 - iter 162/188 - loss 0.15022465 - samples/sec: 58.32 - lr: 0.050000\n",
            "2023-05-14 05:26:17,252 epoch 9 - iter 180/188 - loss 0.14930587 - samples/sec: 59.45 - lr: 0.050000\n",
            "2023-05-14 05:26:21,951 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 05:26:21,951 EPOCH 9 done: loss 0.1493 - lr 0.0500000\n",
            "2023-05-14 05:26:41,418 DEV : loss 0.1274847686290741 - f1-score (micro avg)  0.6896\n",
            "2023-05-14 05:26:41,446 BAD EPOCHS (no improvement): 0\n",
            "2023-05-14 05:26:41,856 saving best model\n",
            "2023-05-14 05:26:48,990 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 05:27:01,787 epoch 10 - iter 18/188 - loss 0.14541302 - samples/sec: 45.03 - lr: 0.050000\n",
            "2023-05-14 05:27:20,051 epoch 10 - iter 36/188 - loss 0.13399837 - samples/sec: 31.55 - lr: 0.050000\n",
            "2023-05-14 05:27:31,417 epoch 10 - iter 54/188 - loss 0.13789168 - samples/sec: 50.70 - lr: 0.050000\n",
            "2023-05-14 05:27:43,221 epoch 10 - iter 72/188 - loss 0.13866944 - samples/sec: 48.81 - lr: 0.050000\n",
            "2023-05-14 05:27:52,210 epoch 10 - iter 90/188 - loss 0.13889958 - samples/sec: 64.11 - lr: 0.050000\n",
            "2023-05-14 05:28:03,641 epoch 10 - iter 108/188 - loss 0.13875100 - samples/sec: 50.41 - lr: 0.050000\n",
            "2023-05-14 05:28:13,501 epoch 10 - iter 126/188 - loss 0.13920192 - samples/sec: 58.44 - lr: 0.050000\n",
            "2023-05-14 05:28:24,317 epoch 10 - iter 144/188 - loss 0.13892180 - samples/sec: 53.27 - lr: 0.050000\n",
            "2023-05-14 05:28:34,194 epoch 10 - iter 162/188 - loss 0.13831033 - samples/sec: 58.34 - lr: 0.050000\n",
            "2023-05-14 05:28:44,300 epoch 10 - iter 180/188 - loss 0.13835037 - samples/sec: 57.03 - lr: 0.050000\n",
            "2023-05-14 05:28:48,046 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 05:28:48,046 EPOCH 10 done: loss 0.1389 - lr 0.0500000\n",
            "2023-05-14 05:29:03,566 DEV : loss 0.12865383923053741 - f1-score (micro avg)  0.7009\n",
            "2023-05-14 05:29:03,598 BAD EPOCHS (no improvement): 0\n",
            "2023-05-14 05:29:03,601 saving best model\n",
            "2023-05-14 05:29:31,608 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 05:29:31,754 loading file resources/taggers/sota-ner-flair/best-model.pt\n",
            "2023-05-14 05:30:29,515 0.8122\t0.7853\t0.7986\t0.6944\n",
            "2023-05-14 05:30:29,515 \n",
            "Results:\n",
            "- F-score (micro) 0.7986\n",
            "- F-score (macro) 0.7156\n",
            "- Accuracy 0.6944\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      LAWYER     0.9520    0.9100    0.9306       589\n",
            "  RESPONDENT     0.8278    0.7937    0.8104       315\n",
            "OTHER_PERSON     0.7323    0.8623    0.7920       276\n",
            "       COURT     0.8696    0.8108    0.8392       296\n",
            "   PROVISION     0.8588    0.8721    0.8654       258\n",
            "     STATUTE     0.8289    0.8514    0.8400       222\n",
            "        DATE     0.9623    0.9189    0.9401       222\n",
            "  PETITIONER     0.8446    0.7725    0.8069       211\n",
            "   PRECEDENT     0.6169    0.7006    0.6561       177\n",
            "         GPE     0.6552    0.6230    0.6387       183\n",
            "       JUDGE     0.8897    0.7414    0.8088       174\n",
            "         ORG     0.5038    0.4214    0.4589       159\n",
            " CASE_NUMBER     0.5899    0.6777    0.6308       121\n",
            "     WITNESS     0.0000    0.0000    0.0000        58\n",
            "\n",
            "   micro avg     0.8122    0.7853    0.7986      3261\n",
            "   macro avg     0.7237    0.7111    0.7156      3261\n",
            "weighted avg     0.8015    0.7853    0.7918      3261\n",
            " samples avg     0.6944    0.6944    0.6944      3261\n",
            "\n",
            "2023-05-14 05:30:29,515 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-14 05:30:29,595 loading file resources/taggers/sota-ner-flair/final-model.pt\n"
          ]
        }
      ]
    }
  ]
}